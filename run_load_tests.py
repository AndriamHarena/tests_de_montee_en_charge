#!/usr/bin/env python3
"""
Script automatisÃ© pour lancer les tests de charge Locust
GÃ©nÃ¨re les rapports HTML et CSV pour validation du plan d'actions correctives
"""

import subprocess
import time
import os
import json
from datetime import datetime

# Configuration des tests pour validation du plan d'actions
TEST_SCENARIOS = {
    "validation": {
        "users": 15,
        "spawn_rate": 3,
        "duration": "60s",
        "description": "Test de validation - charge lÃ©gÃ¨re (baseline)"
    },
    "normal": {
        "users": 30,
        "spawn_rate": 5,
        "duration": "120s",
        "description": "Test normal - charge quotidienne (rÃ©fÃ©rence)"
    },
    "peak": {
        "users": 50,
        "spawn_rate": 8,
        "duration": "180s",
        "description": "Test de pointe - charge Ã©levÃ©e (SLA critique)"
    },
    "stress": {
        "users": 100,
        "spawn_rate": 10,
        "duration": "300s",
        "description": "Test de stress - limite systÃ¨me (point de rupture)"
    }
}

def run_locust_test(scenario_name, host="http://localhost:8000"):
    """
    Lance un test Locust pour un scÃ©nario donnÃ© et gÃ©nÃ¨re les rapports
    """
    scenario = TEST_SCENARIOS[scenario_name]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Noms des fichiers de sortie
    html_report = f"reporting/{scenario_name}_{timestamp}.html"
    csv_report = f"reporting/{scenario_name}_{timestamp}"
    
    # Commande Locust avec tous les paramÃ¨tres nÃ©cessaires
    cmd = [
        "locust",
        "-f", "locustfile.py",
        "--host", host,
        "--users", str(scenario["users"]),
        "--spawn-rate", str(scenario["spawn_rate"]),
        "-t", scenario["duration"],
        "--html", html_report,
        "--csv", csv_report,
        "--headless",
        "--print-stats"
    ]
    
    print(f"ğŸš€ Lancement du test '{scenario_name}': {scenario['description']}")
    print(f"   ğŸ‘¥ Utilisateurs: {scenario['users']} | âš¡ Spawn rate: {scenario['spawn_rate']} | â±ï¸ DurÃ©e: {scenario['duration']}")
    print(f"   ğŸ“Š Rapport HTML: {html_report}")
    print(f"   ğŸ“ˆ Rapport CSV: {csv_report}")
    print(f"   ğŸ”„ Commande: {' '.join(cmd)}")
    
    try:
        # Lancer le test avec affichage en temps rÃ©el
        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        # Afficher la sortie en temps rÃ©el
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                print(f"   ğŸ“Š {output.strip()}")
        
        # Attendre la fin du processus
        return_code = process.poll()
        
        if return_code == 0:
            print(f"âœ… Test '{scenario_name}' terminÃ© avec succÃ¨s")
            return True, html_report, csv_report
        else:
            stderr = process.stderr.read()
            print(f"âŒ Test '{scenario_name}' Ã©chouÃ© (code: {return_code}):")
            print(f"   {stderr}")
            return False, None, None
            
    except subprocess.TimeoutExpired:
        print(f"â° Test '{scenario_name}' interrompu (timeout)")
        return False, None, None
    except Exception as e:
        print(f"ğŸ’¥ Erreur lors du test '{scenario_name}': {e}")
        return False, None, None

def check_api_health(host="http://localhost:8000"):
    """
    VÃ©rifie que l'API est accessible et fonctionnelle avant de lancer les tests
    """
    try:
        import requests
        
        # Test de base - documentation
        response = requests.get(f"{host}/docs", timeout=5)
        if response.status_code != 200:
            print(f"âŒ Documentation API non accessible (status: {response.status_code})")
            return False
        
        # Test d'authentification
        auth_response = requests.post(f"{host}/token", 
                                    data={"username": "admin", "password": "password"},
                                    timeout=5)
        if auth_response.status_code != 200:
            print(f"âŒ Authentification Ã©chouÃ©e (status: {auth_response.status_code})")
            return False
        
        print("âœ… API accessible et fonctionnelle")
        return True
        
    except ImportError:
        print("âš ï¸ Module 'requests' non installÃ©, vÃ©rification basique seulement")
        return True
    except Exception as e:
        print(f"âŒ Impossible de joindre l'API: {e}")
        print("ğŸ’¡ Assurez-vous que l'API est dÃ©marrÃ©e: python -m uvicorn main:app --reload --port 8000")
        return False

def analyze_results(csv_file):
    """
    Analyse rapide des rÃ©sultats CSV pour validation
    """
    try:
        if not os.path.exists(f"{csv_file}_stats.csv"):
            return None
        
        with open(f"{csv_file}_stats.csv", 'r') as f:
            lines = f.readlines()
            if len(lines) < 2:
                return None
            
            # Parser la ligne des stats agrÃ©gÃ©es
            stats_line = lines[-1]  # DerniÃ¨re ligne = agrÃ©gÃ©
            parts = stats_line.split(',')
            
            if len(parts) >= 8:
                return {
                    "requests": int(parts[2]),
                    "failures": int(parts[3]),
                    "avg_response_time": float(parts[5]),
                    "failure_rate": (int(parts[3]) / int(parts[2]) * 100) if int(parts[2]) > 0 else 0
                }
    except Exception as e:
        print(f"âš ï¸ Erreur lors de l'analyse des rÃ©sultats: {e}")
    
    return None

def main():
    """
    Fonction principale - lance tous les tests et gÃ©nÃ¨re le rapport de validation
    """
    print("ğŸ”§ BuyYourKawa API - Tests de Charge pour Plan d'Actions Correctives")
    print("=" * 70)
    print("ğŸ“‹ Objectif: Valider les mÃ©triques avant/aprÃ¨s optimisations")
    print("ğŸ¯ Seuils: Temps < 200ms, Ã‰checs < 2%, DisponibilitÃ© > 99%")
    print("=" * 70)
    
    # CrÃ©er le dossier de rapports s'il n'existe pas
    os.makedirs("reporting", exist_ok=True)
    
    # VÃ©rifier que l'API est accessible
    if not check_api_health():
        return
    
    # Lancer les tests dans l'ordre croissant de charge
    test_results = {}
    
    for scenario_name in ["validation", "normal", "peak", "stress"]:
        print(f"\n{'='*25} {scenario_name.upper()} {'='*25}")
        
        success, html_report, csv_report = run_locust_test(scenario_name)
        
        # Analyser les rÃ©sultats
        analysis = analyze_results(csv_report) if csv_report else None
        
        test_results[scenario_name] = {
            "success": success,
            "html_report": html_report,
            "csv_report": csv_report,
            "analysis": analysis
        }
        
        if success and analysis:
            print(f"ğŸ“Š RÃ©sultats rapides:")
            print(f"   ğŸ“ˆ RequÃªtes totales: {analysis['requests']}")
            print(f"   âŒ Ã‰checs: {analysis['failures']} ({analysis['failure_rate']:.1f}%)")
            print(f"   â±ï¸ Temps moyen: {analysis['avg_response_time']:.0f}ms")
            print(f"   ğŸ“„ Rapport dÃ©taillÃ©: {html_report}")
            
            # Validation des seuils
            if analysis['avg_response_time'] > 200:
                print(f"   âš ï¸ SEUIL DÃ‰PASSÃ‰: Temps de rÃ©ponse > 200ms")
            if analysis['failure_rate'] > 2:
                print(f"   âš ï¸ SEUIL DÃ‰PASSÃ‰: Taux d'Ã©chec > 2%")
        
        # Pause entre les tests pour Ã©viter la surcharge
        if scenario_name != "stress":
            print("â³ Pause de 15 secondes avant le test suivant...")
            time.sleep(15)
    
    # RÃ©sumÃ© final avec validation des seuils
    print("\n" + "="*70)
    print("ğŸ“‹ RÃ‰SUMÃ‰ DES TESTS - VALIDATION PLAN D'ACTIONS")
    print("="*70)
    
    for scenario, result in test_results.items():
        status = "âœ… SUCCÃˆS" if result["success"] else "âŒ Ã‰CHEC"
        print(f"{scenario.ljust(12)} : {status}")
        
        if result["success"] and result["analysis"]:
            analysis = result["analysis"]
            print(f"             ğŸ“Š {analysis['requests']} req | âŒ {analysis['failure_rate']:.1f}% Ã©checs | â±ï¸ {analysis['avg_response_time']:.0f}ms")
            print(f"             ğŸ“„ {result['html_report']}")
            
            # Validation des seuils critiques
            if analysis['avg_response_time'] > 500:
                print(f"             ğŸš¨ CRITIQUE: Temps > 500ms")
            elif analysis['avg_response_time'] > 200:
                print(f"             âš ï¸ ATTENTION: Temps > 200ms")
            
            if analysis['failure_rate'] > 5:
                print(f"             ğŸš¨ CRITIQUE: Ã‰checs > 5%")
            elif analysis['failure_rate'] > 2:
                print(f"             âš ï¸ ATTENTION: Ã‰checs > 2%")
    
    print("\nğŸ¯ Tests terminÃ©s !")
    print("ğŸ’¡ Consultez les rapports HTML dÃ©taillÃ©s dans le dossier 'reporting/'")
    print("ğŸ“Š Utilisez ces mÃ©triques pour valider l'efficacitÃ© du plan d'actions correctives")

if __name__ == "__main__":
    main()
